# MapReduce

## Data
- We create a lot of data
- But some of it is retained, not all of it

## Storing in the cloud
- Store for a reason, to process or extraxt info
- The cloud computing enables data storage at a greater scale
- Cloud storage can be:
    - Structured (SQL)
    - Semi-Structured (XML, JSON)
    - Unstructured (BLOB)
- Most cloud storage systems can store many hundreds of petabytes or even exabytes of data

## Problem
So we want to "process" some data stored at the *cloud scale*. The chances are that the processing is too computationally expensive for one machine or that we have too much data to fit on one machinbe.

## Batch Processing
- If we have a "shitton" of data we will divide and conqueror
- Divide the dataset into some manageable chunks, process the chunks separately
- Medicaid processing: service claims are submitted in batch files, Medicaid clearing house processes batches one at a time, sometimes hours after submissions
    - "How do I know this? I wrote a system in 200....9 that did this" - Aleksey

### Parallel Batches
- Processing one at a time is slow
- Throw more compute resources (servers, workers) to do many batches at once
- This can cause problems if something depends on something else in a different batch
- If batches are independent, we can speed up to an almost linear speed

## MapReduce
- Leverage concurrency without programmers knowing about parallel programming
- This will take forever, so you need a LOT of data for it to work properly
- Read: [*MapReduce: Simplified Data Processing on Large Clusters*](https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf)
- MapReduce Structures the computation to maximize parallelism for problems that require synchronization (the problems with dependencies across batches)

### Step 1: Map Phase
- Input
    - Set of `input_key -> input_value` pairs
- Output
    - Set of `output_key -> output_value` pairs
- Goal
    - "Move" from the domain of the input to the domain of the output
- Example: `Document -> Words` to `Words -> Count`
    - Doc1: `w1, w2, w1` -> `[w1:1, w2:1, w1:1]`
    - Doc2: `w2 w3` -> `[w2: 1, w3: 1]`
    - Doc3: `w3 w1` -> `[w3: 1, w1: 1]`

### Shuffle
- This is a synchronization point of the computation
- MapReduce systems store the intermediate results
- When all Mappers are done, the intermediate results are shuffled and delivered into the reducers
    - Shuffle rules: Deliver all intermediate results for the same key to the same reducer
- Example:
    - Input: `[w1:1, w2:1, w1:1]`, `[w2: 1, w3: 1]`, `[w3: 1, w1: 1]`
    - Output: `[w1:1, w1:1, w1:1]`, `[w2:1, w2:1]`, `[w3:1, w3:]`
- Shuffle can be smart:
    - Use a distributed storage system
    - As soon as I see w1, send it to a particular disk
    - Have all w1 on the same file system but mapped to machine X
    - Put worker on machine X so it reads from that and does stuff
    - Therefore setting up the reduce phase for optimizations
    - If everything is properly distributed, we can shuffle as we get data, reducing the total time to shuffle

### Step 2: Reduce Phase
- Takes an output key and all values for that key
- Merges or reduces the values together
- Example:
    - Input: `[w1:1, w1:1, w1:1]`, `[w2:1, w2:1]`, `[w3:1, w3:]`
    - Output `w1:3`, `w2:2`, `w3:2`

## Chaining MapReduce
- MapReduce can be chained to get longer processing pielines, an output of a reduce phase becomes an input to some stage
    - Chain full map -> reduce computations
    - Chain multiple stages map -> reduce -> reduce
- Useful for iterative algorithms (PageRank) or longer compute pipelines

## Why MapReduce?
- Allows engineers who know nothing about concurrent/parallel programming to write highly scalable data processing pipelines
- Lverages scale of data centers, can use many simpler/smaller worker machines instead of high-end expensive computers
- More recently: can leverage unused/temporary capacity of the cloud
    - Business server by day, MapReduce by night

## Downsides of MapReduce
- Shuffle is expensive, all intermediate results are saved to some disk and physically moved around
- Outputs are saved as well
- Reliance on saving all steps to disk makes iterative algorithms slow
    - Hurts machine learning
    - "That becomes pain in ass" - Aleksey
- Problems with incremental processing

## MapReduce Example: Inverted Index
- Search for a website based off of content of a website
- Search engines use this!!
- Input: `id --> text`
    - `id=1; Cloud rocks`
    - `id=2; Professor Aleksey works with databases`
    - `id=3; Cloud dayabases are big`
    - `id=4; Aleksey teaches cloud computing`
- Map
    - Data into domain of output
    - Mappers
        1. `cloud: 1, rocks: 1, professor: 2, aleksey: 2, works: 2, databases: 2`
        2. `cloud: 3, databases: 3, big: 3, aleksey: 4, teaches: 4, cloud: 4, computing: 4`

- Shuffle
    - `cloud: 1, cloud: 3, cloud: 4, rocks: 1, professor: 2, aleksey: 2, aleksey: 4`
    - `works: 2, databases: 2, databases: 4, big: 3, teaches: 4, computing: 4`
- Reduce
    - `cloud: 1, 3, 4`, `rocks: 1`, `professor: 2`,  `aleksey: 2, 4`, `works: 2`
    - `databases: 3, 4`, `big: 3`, `teaches: 4`, `computing: 4`

## Look In To
- Azure Durable Functions
- azure-samples/durablefunctions-mapreduce-dotnet
- S3